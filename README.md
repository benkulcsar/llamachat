# ğŸ¦™llamachat  
[![python](https://img.shields.io/badge/python-3.13-blue?style=flat&logo=python&logoColor=white)](https://www.python.org)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Learning & experimenting with local open-weight LLMs**

Simulated chat between two users roleplayed by [Gemma 3 4B Q4_0](https://ollama.com/library/gemma3:4b) using Ollama. Different scenarios can be configured in a YAML file. 

The model performs surprisingly well on an older Intel i5 CPU without a GPU.

![This GIF is missing. But it's a good opportunity to remind everyone it's pronounced GIF, not JIF.](./assets/llamachat.gif)

## Requirements

- Docker & Docker Compose
- Tested on Ubuntu 20.04 and 22.04

## Workflow

```shell
make build
make up
make run
make down
```

## Development

Run lint (runs black and mypy too) and tests:

```shell
make lint
make test
```

## Scenarios

### Puppies and Emojis

```shell
$ make run scenario=emopuppy
```

<details>
<summary>Example Result</summary>


```shell
Bingo: ğŸ‘‹ğŸ’–
Bluey: ğŸ¾ğŸ¥°
Bingo: ğŸ¾ğŸ˜†ğŸ’–! ğŸ¦´ğŸ¤¸â€â™€ï¸
Bluey: ğŸ˜†ğŸ’–ğŸ¤¸â€â™€ï¸ğŸ¾ğŸ¥°! ğŸ¦´ğŸ¥³ğŸ’–ğŸ¾!
Bingo: ğŸ¾ğŸ¥°ğŸ¤¸â€â™€ï¸ğŸ¥³ğŸ’–! ğŸ¦´ğŸ˜†ğŸ¤¸â€â™€ï¸ğŸ’–! ğŸ¾ğŸ˜†ğŸ¥°ğŸ¤¸â€â™€ï¸ğŸ¥³! ğŸ¦´ğŸ’–ğŸ¾ğŸ¥°!
Bluey: ğŸ˜†ğŸ’–ğŸ¾ğŸ¤¸â€â™€ï¸ğŸ¥³! ğŸ¦´ğŸ¥°ğŸ¤¸â€â™€ï¸ğŸ’–! ğŸ¾ğŸ˜†ğŸ¤¸â€â™€ï¸ğŸ¥³! ğŸ¦´ğŸ’–ğŸ¾ğŸ¥°! ğŸ¥³ğŸ’–ğŸ¾ğŸ¤¸â€â™€ï¸! ğŸ¦´ğŸ˜†ğŸ¤¸â€â™€ï¸ğŸ’–!
Bingo: ğŸ¾ğŸ˜†ğŸ’–! ğŸ¤¸â€â™€ï¸ğŸ¥³ğŸ¦´! ğŸ¾ğŸ¥°ğŸ¤¸â€â™€ï¸ğŸ’–! ğŸ¦´ğŸ˜†ğŸ¤¸â€â™€ï¸ğŸ¥³! ğŸ¾ğŸ¥°ğŸ¤¸â€â™€ï¸ğŸ¥³! ğŸ¥³ğŸ’–ğŸ¾ğŸ¤¸â€â™€ï¸! ğŸ¦´ğŸ˜†ğŸ¤¸â€â™€ï¸ğŸ’–! ğŸ˜ŠğŸ¾ğŸ’–!
Bluey: ğŸ¤¸â€â™€ï¸ğŸ¥³ğŸ¾ğŸ˜†ğŸ’–! ğŸ¦´ğŸ¥°ğŸ¤¸â€â™€ï¸ğŸ¥³! ğŸ¾ğŸ˜†ğŸ¤¸â€â™€ï¸ğŸ¥³! ğŸ¦´ğŸ’–ğŸ¾ğŸ¥°! ğŸ˜ŠğŸ¤¸â€â™€ï¸ğŸ’–ğŸ¾! ğŸ¥³ğŸ˜†ğŸ¤¸â€â™€ï¸ğŸ’–! ğŸ¦´ğŸ¤¸â€â™€ï¸ğŸ¥³ğŸ¥°!
Bingo: ğŸ˜†ğŸ’–ğŸ¤¸â€â™€ï¸ğŸ¾ğŸ¥°! ğŸ¥³ğŸ¤¸â€â™€ï¸ğŸ¾ğŸ˜†ğŸ’–! ğŸ¦´ğŸ’–ğŸ¤¸â€â™€ï¸ğŸ¥³! ğŸ¾ğŸ˜†ğŸ¤¸â€â™€ï¸ğŸ¥³! ğŸ¦´ğŸ¤¸â€â™€ï¸ğŸ¥°ğŸ’–! ğŸ˜ŠğŸ¤¸â€â™€ï¸ğŸ¾ğŸ’–!
Bluey: ğŸ¤¸â€â™€ï¸ğŸ¥³ğŸ’–ğŸ¦´! ğŸ¾ğŸ˜†ğŸ¥°ğŸ¤¸â€â™€ï¸ğŸ¥³! ğŸ˜ŠğŸ¤¸â€â™€ï¸ğŸ’–ğŸ¾! ğŸ¥³ğŸ’–ğŸ¾ğŸ¤¸â€â™€ï¸! ğŸ¦´ğŸ˜†ğŸ¤¸â€â™€ï¸ğŸ’–! ğŸ¤¸â€â™€ï¸ğŸ¥³ğŸ¥°! ğŸ˜ŠğŸ¾ğŸ’–! ğŸ¤¸â€â™€ï¸ğŸ¥³ğŸ¦´! ğŸ¾ğŸ˜†ğŸ¤¸â€â™€ï¸ğŸ¥³! ğŸ¥³ğŸ’–ğŸ¾ğŸ¤¸â€â™€ï¸! ğŸ¤¸â€â™€ï¸ğŸ¥³ğŸ’–! ğŸ˜ŠğŸ¤¸â€â™€ï¸ğŸ¥³! ğŸ¤¸â€â™€ï¸ğŸ¥³ğŸ’–!
Bingo: ğŸ˜†ğŸ’–ğŸ¾ğŸ¤¸â€â™€ï¸ğŸ¥³! ğŸ¦´ğŸ¥°ğŸ¤¸â€â™€ï¸ğŸ’–! ğŸ¾ğŸ˜†ğŸ¤¸â€â™€ï¸ğŸ¥³! ğŸ¥³ğŸ’–ğŸ¾ğŸ¤¸â€â™€ï¸! ğŸ¤¸â€â™€ï¸ğŸ˜†ğŸ’–! ğŸ˜ŠğŸ¾ğŸ’–! ğŸ¤¸â€â™€ï¸ğŸ¥³ğŸ¦´! ğŸ¾ğŸ¥°ğŸ¤¸â€â™€ï¸ğŸ¥³! ğŸ¥³ğŸ’–ğŸ¾ğŸ¤¸â€â™€ï¸! ğŸ¤¸â€â™€ï¸ğŸ¥³ğŸ’–! ğŸ˜ŠğŸ¤¸â€â™€ï¸ğŸ¥³! ğŸ¤¸â€â™€ï¸ğŸ¥³ğŸ’–!
```

</details>

### Rick and Lisa Discussing Science

```shell
$ make run scenario=science
```

<details>
<summary>Example Result</summary>


```shell
Rick: Hey Lisa, what's up? ğŸ¤ª

Lisa: Hello. Iâ€™ve been reviewing the latest advancements in transformer models. Specifically, the scaling laws are proving remarkably consistent, suggesting a predictable trajectory for performance improvements. Itâ€™s fascinating, though I remain cautious about over-interpretation. What have you been investigating?

Rick: ğŸ¤¯ Scaling laws are wild! I'm chasing diffusion models. ğŸ¨ It's like magic! âœ¨ What's your take? ğŸ¤”

Lisa: Interesting. The sheer scale of these transformer models isâ€¦ concerning, frankly. The computational cost alone is staggering. I'm focusing on the limitations of attention mechanisms â€“ the quadratic scaling with sequence length. It presents significant bottlenecks. Diffusion models, I acknowledge, offer an alternative approach. Do you believe they truly circumvent the fundamental computational constraints, or are they simply shifting the problem?

Rick: Massive! ğŸ¤¯ Scaling is scary. But diffusion? Genius! ğŸ¨ Clever workaround. ğŸ‘ Keep exploring! ğŸš€

Lisa: Indeed. The probabilistic nature of diffusion offers a potential path. However, Iâ€™m skeptical of their long-term robustness. The reliance on stochastic processes introduces inherent variability. Are you seeing evidence of this in your experiments? Specifically, Iâ€™m examining the effect of noise schedules on sample quality versus training efficiency. Itâ€™s proving a complex interplay.
(...)
```

</details>
